{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0058a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gt_json = {\n",
    "  \"age\": 54,\n",
    "  \"height\": 1.75,\n",
    "  \"weight\": 90,\n",
    "  \"bmi\": 29.4,\n",
    "  \"diagnoses\": [\n",
    "    \"Hypertension artérielle contrôlée sous médication depuis 10 ans\",\n",
    "    \"Hypercholestérolémie\",\n",
    "    \"Historique familial de maladie coronarienne (père décédé d'un infarctus du myocarde à l'âge de 60 ans)\"\n",
    "  ],\n",
    "  \"allergies\": [\"Latex\"]\n",
    "}\n",
    "\n",
    "\n",
    "mistake_json = {\n",
    "  \"age\": 54,\n",
    "  \"height\": 1.75,\n",
    "  \"weight\": 1.75,\n",
    "  \"bmi\": 1.75,\n",
    "  \"diagnoses\": [\n",
    "    \"Hypertension artérielle contrôlée sous médication depuis 10 ans\",\n",
    "    \"Historique familial de maladie coronarienne (père décédé d'un infarctus du myocarde à l'âge de 60 ans)\"\n",
    "  ],\n",
    "  \"allergies\": [\"Hypercholestérolémie\", \"Latex\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b855fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hypertension artérielle contrôlée sous médication depuis 10 ans', 'Hypercholestérolémie', \"Historique familial de maladie coronarienne (père décédé d'un infarctus du myocarde à l'âge de 60 ans)\"] ['Hypertension artérielle contrôlée sous médication depuis 10 ans', \"Historique familial de maladie coronarienne (père décédé d'un infarctus du myocarde à l'âge de 60 ans)\"]\n",
      "['Latex'] ['Hypercholestérolémie', 'Latex']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32999148955420154"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embedder = SentenceTransformerEmbeddings(\n",
    "        model_name=\"dangvantuan/sentence-camembert-large\",\n",
    "    )\n",
    "\n",
    "def semantic_similarity(list1, list2, embedder):\n",
    "    \"\"\"\n",
    "    Calculate semantic similarity between two lists of strings using embeddings.\n",
    "    \n",
    "    Args:\n",
    "    - list1: A list of strings.\n",
    "    - list2: A list of strings.\n",
    "    - embedder: An instance of SentenceTransformerEmbeddings.\n",
    "\n",
    "    Returns:\n",
    "    - A float representing the semantic similarity score between the two lists.\n",
    "    \"\"\"\n",
    "    # Generate embeddings for each string in the lists\n",
    "    # Assuming embedder.embed_query supports batch processing directly for lists of strings\n",
    "    embeddings1 = np.array([embedder.embed_query(text) for text in list1])   \n",
    "    embeddings2 = np.array([embedder.embed_query(text) for text in list2])\n",
    "    \n",
    "    # Calculate cosine similarities between each pair of embeddings\n",
    "    similarity_matrix = cosine_similarity(embeddings1, embeddings2)\n",
    "    \n",
    "    # For each item in list1, find the max similarity score with items in list2, and vice versa\n",
    "    max_similarities_1 = similarity_matrix.max(axis=1)\n",
    "    max_similarities_2 = similarity_matrix.max(axis=0)\n",
    "    \n",
    "    # Calculate the mean of the max similarities as the overall semantic similarity score\n",
    "    mean_similarity = (np.mean(max_similarities_1) + np.mean(max_similarities_2)) / 2\n",
    "    \n",
    "    return mean_similarity\n",
    "\n",
    "\n",
    "def calculate_overlap_coefficient(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    intersection_size = len(set1.intersection(set2))\n",
    "    smaller_set_size = min(len(set1), len(set2))\n",
    "    return intersection_size / smaller_set_size if smaller_set_size > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_correctness(gt_json, mistake_json):\n",
    "    score, penalties, max_score = 0, 0, 0\n",
    "\n",
    "    for key, value in gt_json.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            max_score += 1\n",
    "            if key in mistake_json and mistake_json[key] == value:\n",
    "                score += 1\n",
    "            elif key not in mistake_json or type(value) != type(mistake_json.get(key, \"\")) or mistake_json.get(key, 0) <= 0:\n",
    "                penalties += 1\n",
    "        elif isinstance(value, list) and value and isinstance(value[0], str):\n",
    "            max_score += 2  # Adjusting for semantic comparison\n",
    "            if key in mistake_json and isinstance(mistake_json[key], list):\n",
    "                if set(value) == set(mistake_json[key]):\n",
    "                    score += 1\n",
    "                else:\n",
    "                    # Apply semantic similarity comparison for each item in the list\n",
    "                    semantic_score = semantic_similarity(value, mistake_json[key], embedder)\n",
    "                    score += semantic_score\n",
    "            else:\n",
    "                penalties += 1\n",
    "\n",
    "    correctness_percentage = ((score - penalties) / max_score) if max_score else 0\n",
    "    return correctness_percentage\n",
    "\n",
    "\n",
    "calculate_correctness(gt_json, mistake_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0dd0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
